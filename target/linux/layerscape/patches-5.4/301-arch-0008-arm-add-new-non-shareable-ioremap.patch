From e5bf75ca33946d81c82014168042a64db7c81551 Mon Sep 17 00:00:00 2001
From: Pan Jiafei <Jiafei.Pan@nxp.com>
Date: Thu, 17 Mar 2016 02:01:03 +0000
Subject: [PATCH] arm: add new non-shareable ioremap

Signed-off-by: Pan Jiafei <Jiafei.Pan@nxp.com>
Signed-off-by: Roy Pledge <roy.pledge@nxp.com>
---
 arch/arm/include/asm/io.h       | 3 +++
 arch/arm/include/asm/mach/map.h | 4 ++--
 arch/arm/mm/ioremap.c           | 7 +++++++
 arch/arm/mm/mmu.c               | 9 +++++++++
 4 files changed, 21 insertions(+), 2 deletions(-)

--- a/arch/arm/include/asm/io.h
+++ b/arch/arm/include/asm/io.h
@@ -123,6 +123,7 @@ static inline u32 __raw_readl(const vola
 #define MT_DEVICE_NONSHARED	1
 #define MT_DEVICE_CACHED	2
 #define MT_DEVICE_WC		3
+#define MT_MEMORY_RW_NS		4
 /*
  * types 4 onwards can be found in asm/mach/map.h and are undefined
  * for ioremap
@@ -438,6 +439,8 @@ void __iomem *ioremap_wc(resource_size_t
 #define ioremap_wc ioremap_wc
 #define ioremap_wt ioremap_wc
 
+void __iomem *ioremap_cache_ns(resource_size_t res_cookie, size_t size);
+
 void iounmap(volatile void __iomem *iomem_cookie);
 #define iounmap iounmap
 
--- a/arch/arm/include/asm/mach/map.h
+++ b/arch/arm/include/asm/mach/map.h
@@ -18,9 +18,9 @@ struct map_desc {
 	unsigned int type;
 };
 
-/* types 0-3 are defined in asm/io.h */
+/* types 0-4 are defined in asm/io.h */
 enum {
-	MT_UNCACHED = 4,
+	MT_UNCACHED = 5,
 	MT_CACHECLEAN,
 	MT_MINICLEAN,
 	MT_LOW_VECTORS,
--- a/arch/arm/mm/ioremap.c
+++ b/arch/arm/mm/ioremap.c
@@ -399,6 +399,13 @@ void __iomem *ioremap_wc(resource_size_t
 }
 EXPORT_SYMBOL(ioremap_wc);
 
+void __iomem *ioremap_cache_ns(resource_size_t res_cookie, size_t size)
+{
+	return arch_ioremap_caller(res_cookie, size, MT_MEMORY_RW_NS,
+				   __builtin_return_address(0));
+}
+EXPORT_SYMBOL(ioremap_cache_ns);
+
 /*
  * Remap an arbitrary physical address space into the kernel virtual
  * address space as memory. Needed when the kernel wants to execute
--- a/arch/arm/mm/mmu.c
+++ b/arch/arm/mm/mmu.c
@@ -312,6 +312,13 @@ static struct mem_type mem_types[] __ro_
 		.prot_sect = PMD_TYPE_SECT | PMD_SECT_AP_WRITE,
 		.domain    = DOMAIN_KERNEL,
 	},
+	[MT_MEMORY_RW_NS] = {
+		.prot_pte  = L_PTE_PRESENT | L_PTE_YOUNG | L_PTE_DIRTY |
+			     L_PTE_XN,
+		.prot_l1   = PMD_TYPE_TABLE,
+		.prot_sect = PMD_TYPE_SECT | PMD_SECT_AP_WRITE | PMD_SECT_XN,
+		.domain    = DOMAIN_KERNEL,
+	},
 	[MT_ROM] = {
 		.prot_sect = PMD_TYPE_SECT,
 		.domain    = DOMAIN_KERNEL,
@@ -648,6 +655,7 @@ static void __init build_mem_type_table(
 	}
 	kern_pgprot |= PTE_EXT_AF;
 	vecs_pgprot |= PTE_EXT_AF;
+	mem_types[MT_MEMORY_RW_NS].prot_pte |= PTE_EXT_AF | cp->pte;
 
 	/*
 	 * Set PXN for user mappings
@@ -676,6 +684,7 @@ static void __init build_mem_type_table(
 	mem_types[MT_MEMORY_RWX].prot_pte |= kern_pgprot;
 	mem_types[MT_MEMORY_RW].prot_sect |= ecc_mask | cp->pmd;
 	mem_types[MT_MEMORY_RW].prot_pte |= kern_pgprot;
+	mem_types[MT_MEMORY_RW_NS].prot_sect |= ecc_mask | cp->pmd;
 	mem_types[MT_MEMORY_DMA_READY].prot_pte |= kern_pgprot;
 	mem_types[MT_MEMORY_RWX_NONCACHED].prot_sect |= ecc_mask;
 	mem_types[MT_ROM].prot_sect |= cp->pmd;
